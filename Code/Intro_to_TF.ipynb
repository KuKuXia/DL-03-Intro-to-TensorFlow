{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在终端执行程序时指定GPU   \n",
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=1   python  your_file.py\n",
    "```\n",
    "这样在跑你的网络之前，告诉程序只能看到1号GPU，其他的GPU它不可见\n",
    "可用的形式如下：\n",
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=1           Only device 1 will be seen\n",
    "CUDA_VISIBLE_DEVICES=0,1         Devices 0 and 1 will be visible\n",
    "CUDA_VISIBLE_DEVICES=\"0,1\"       Same as above, quotation marks are optional\n",
    "CUDA_VISIBLE_DEVICES=0,2,3       Devices 0, 2, 3 will be visible; device 1 is masked\n",
    "CUDA_VISIBLE_DEVICES=\"\"          No GPU will be visible\n",
    "```\n",
    "\n",
    "\n",
    "## 在Python代码中指定GPU\n",
    "```python\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "```\n",
    "\n",
    "\n",
    "## 设置定量的GPU使用量\n",
    "```python\n",
    "config = tf.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9 # 占用GPU90%的显存 \n",
    "session = tf.Session(config=config)\n",
    "```\n",
    "\n",
    "\n",
    "## 设置最小的GPU使用量\n",
    "```python\n",
    "config = tf.ConfigProto() \n",
    "config.gpu_options.allow_growth = True \n",
    "session = tf.Session(config=config)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf   # 导入Package\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # 选择GPU\n",
    "config = tf.ConfigProto() # 设置GPU显存比列\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6 # 占用GPU90%的显存 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "# Create TensorFlow object called hello_constant\n",
    "hello_constant = tf.constant('Hello World!')\n",
    "\n",
    "with tf.Session(config=config) as sess:  # 添加session的配置\n",
    "    # Run the tf.constant operation in the session\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A is a 0-dimensional int32 tensor\n",
    "A = tf.constant(1234)\n",
    "# B is a 1-dimensional int32 tensor\n",
    "B = tf.constant([123, 456, 789])\n",
    "# C is a 2-dimensional int32 tensor\n",
    "C = tf.constant([[123, 456, 789], [222, 333, 444]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.string)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Hello World'})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8360188   0.11314284  0.05083836]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    # TODO: Compute and return softmax(x)\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "\n",
    "logits = [3.0, 1.0, 0.2]\n",
    "print(softmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95367431640625\n"
     ]
    }
   ],
   "source": [
    "a = 1000000000\n",
    "for i in range(1000000):\n",
    "    a = a + 1e-6\n",
    "print(a - 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.080000000000001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5.9*6/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-12a43bce77eb>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/longxiajun/Software/Anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/longxiajun/Software/Anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./datasets/ud730/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/longxiajun/Software/Anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/longxiajun/Software/Anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/longxiajun/Software/Anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('./datasets/ud730/mnist', one_hot=True)\n",
    "\n",
    "# The features are already scaled and the data is shuffled\n",
    "train_features = mnist.train.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(784, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(weights.shape)\n",
    "print(bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164.48974609375 MB\n",
      "2.09808349609375 MB\n",
      "0.0299072265625 MB\n",
      "3.814697265625e-05 MB\n",
      "Total number of memory is:  166.6177749633789\n"
     ]
    }
   ],
   "source": [
    "train_features_size_MB = train_features.shape[0] * \\\n",
    "    train_features.shape[1] * 4.0 / 1024 / 1024\n",
    "train_labels_size_MB = train_labels.shape[0] * \\\n",
    "    train_labels.shape[1] * 4.0 / 1024 / 1024\n",
    "weights_size_MB = int(weights.shape[0] * weights.shape[1] * 4.0) / 1024 / 1024\n",
    "bias_size_MB = int(bias.shape[0] * 4.0) / 1024 / 1024\n",
    "total = train_features_size_MB + \\\n",
    "    train_labels_size_MB + weights_size_MB + bias_size_MB\n",
    "print(train_features_size_MB, 'MB')\n",
    "print(train_labels_size_MB, 'MB')\n",
    "print(weights_size_MB, 'MB')\n",
    "print(bias_size_MB, 'MB')\n",
    "print('Total number of memory is: ', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3136"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "31360/1024\n",
    "784*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000//128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000%128"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
